# Factuality LLM-as-a-Judge Evaluation Summary

**Examples used:** 5
**Examples failed:** 0

## Metrics

### Binary Classification

- **True Positives (TP):** 2
- **False Positives (FP):** 1
- **True Negatives (TN):** 2
- **False Negatives (FN):** 0

### Performance Metrics (95% CI, Bootstrap n=200)

- **Precision:** 0.6667 [0.4000, 0.9000]
- **Recall:** 1.0000 [0.8000, 1.0000]
- **F1:** 0.8000 [0.6000, 0.9500]
- **Balanced Accuracy:** 0.8333 [0.6000, 1.0000]
- **Specificity:** 0.6667
- **Accuracy:** 0.8000
- **MCC:** 0.6325
- **AUROC:** 0.9167 (computed on confidence scores)

## Parse Statistics

- **Parsed JSON (OK):** 5 (100.0%)
- **Parsed Regex (Fallback):** 0 (0.0%)
- **Parse Failed:** 0 (0.0%)

**Note:** JSON parsing is primary; regex extraction is fallback only.

## Cache Statistics

- **Cache Mode:** off
- **Cache Hits:** 0
- **Cache Misses:** 5

